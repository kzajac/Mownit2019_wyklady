\section{Wzór rekurencyjny Clenshawa}
%%%%%%%%%%%%%%%%%%%
\begin{frame}{Clenshaw's recurrence formula}
	Elegancki i efektywny sposób sumowania wyrazów spełniających pewien wzór rekurencyjny:
    $$f(x) = \sum_{k=0}^{N}c_kF_k(x)$$
    przy czym $c_k$ znane oraz $F(x)$ - spełnia wzór rekurencyjny:
    $$F_{n+1}(x) = \alpha(n,x) \cdot F_n(x) + \beta(n,x) \cdot F_{n-1}(x)$$
   gdzie: $\alpha(n,x),\beta(n,x)$ - pewne funkcje\newline
   Przykładem takiej sumy jest suma stosowana przy wyznaczaniu współczynników dla interpolacji Czebyszewa.
\end{frame}
\begin{frame}
Jak działa?\\

    Określamy rekurencyjnie  pomocnicze zmienne $y_k,k = N,N-1,..,1$ (downward order; k - decreasing) jako:
    $$y_{N+2}=y_{N+1} = 0, y_k(x) = \alpha(k,x) \cdot y_{k+1}+\beta(k+1,x) \cdot y_{k+2}+c_k$$
    
    Stąd wyliczamy zależność: $c_k = y_k - \alpha(k,x) \cdot y_{k+1} - \beta(k+1,x) \cdot y_{k+2}$ \newline
\end{frame} 
%%%%%%%%%%%%%%%%%%%
\begin{frame}
	Po podstawieniu otrzymujemy:
    $$f(x) = \sum_{k=N}^{0}[y_k-\alpha(k,x)y_{k+1}-\beta(k+1,x)y_{k+2}] \cdot F_k(x) = $$
    $$\left.\begin{array}{rcccccl}
    	=[ & y_N & - & 0 & - & 0 & ] F_N(x) \\
        +[ &y_{N-1}& - & \alpha(N-1,x)\cdot y_N & - & 0 & ] F_{N-1}(x) \\
         & \ldots & & \ldots & & \ldots & \\
         +[ & \textrm{\colorbox{red}{$y_8$}} & - & \alpha(8,x)y_9 & - & \beta(9,x)y_{10} & ] \textrm{\colorbox{red}{$F_8(x)$}} \\
		+[ & y_7 & - & \textrm{\colorbox{red}{$\alpha(7,x)y_8$}} & - & \beta(8,x)y_9 & ] \textrm{\colorbox{red}{$F_7(x)$}} \\
        +[ & y_6 & - & \alpha(6,x)y_7 & - & \textrm{\colorbox{red}{$\beta(7,x)y_8$}} & ] \textrm{\colorbox{red}{$F_6(x)$}} \\
        +[ & y_5 & - & \alpha(5,x)y_6 & - & \beta(6,x)y_7 & ] F_5(x) \\
         & \ldots & & \ldots & & \ldots & \\
		+[ & y_2 & - & \alpha(2,x)y_3 & - & \beta(3,x)y_4 & ] F_2(x) \\
        +[ & y_1 & - & \alpha(1,x)y_2 & - & \beta(2,x)y_3 & ] F_1(x) \\
        +[ & y_0 & - & \alpha(0,x)y_1 & - & \beta(1,x)y_2 & ] F_0(x) =
    \end{array}\right.$$
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
"Czerwone" składniki dają:
$$y_8[F_8(x)-\alpha(7,x)F_7(x)-\beta(7,x)F_6(x)]$$
ponieważ z założenia $F_8(x)=\alpha(7,x)F_7(x)+\beta(7,x)F_6(x)$ to
"czerwone" składniki się zerują.\\
Jedynymi składnikami, które pozostaną są te w "dolnym lewym trójkącie" czyli:
$$(*)y_1F_1(x)+[y_0-\alpha(0,x)y_1]F_0(x)$$
Ponieważ $c_0=y_0-\alpha(0,x)y_1-\beta(1,x)y_2$ to
(*) można przekształcić do: 
	$$F_1(x)y_1+\beta(1,x)y_2F_0(x)+c_0F_0(x) $$
\end{frame}
\begin{frame}
    Tak więc wyznaczanie $f(x) = \sum_{k=0}^{N}c_kF_k(x)$ \newline
    dla $F_k(x)$: $F_{n+1}(x) = \alpha(n,x) \cdot F_n(x) + \beta(n,x) \cdot F_{n-1}(x)$ \newline
    sprowadza się do:
    \begin{enumerate}
    \item wyznaczenia $y_1$ i $y_2$ z formuły rekurencyjnej: \newline
    	$$\left\{\begin{array}{l}
    	y_{N+2} = y_{N+1} = 0 \\
        y_k(x) = \alpha(k,x) \cdot y_{k+1} + \beta(k+1,x) \cdot y_{k+2} +c_k
    	\end{array}\right.$$
     \item obliczenia sumy \newline
     $$f(x) = \beta(1,x) \cdot y_2(x) \cdot F_0(x) + y_1(x) \cdot F_1(x) + c_0 \cdot F_0(x)$$
    \end{enumerate}
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}{Clenshaw's recurrence in upward direction:}
    W zależności od róznic pomiędzy 
    $$\left.\begin{array}{cl}
    	F_k(x) & \text{dla małych i dużych k} \\
        c_k & \text{dla małych i duzych k}
    \end{array}$$
    może mieć znaczenie, czy 
    współczynniki $y_k$ są liczone  od większych do mniejszych $k$, czy na odwrót.\\ 
    Wykrywanie  utraty dokładności:\\
    $\beta(1,x) \cdot y_2 \cdot F_0 \text{ oraz } y_1 \cdot F_1$ - przeciwnych znaków i prawie równe
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
	Wtedy stosować \textbf{Clenshaw's recurrence in upward direction:}
    $$y_{-2} = y_{-1} = 0$$
    $$y_k = \frac{1}{\beta(k+1,x)}[y_{k-2}-\alpha(k,x)y_{k-1} - c_k], k=0,1..,N-1$$
    $$f(x) = c_NF_N(x) - \beta(B,x)F_{N-1}(x)y_{N-1} - F_N(x)y_{N-2}$$
    
    \url{https://www.ams.org/journals/mcom/1955-09-051/S0025-5718-1955-0071856-0/S0025-5718-1955-0071856-0.pdf}
    
\end{frame}
%%%%%%%%%%%%%%%%%%%
